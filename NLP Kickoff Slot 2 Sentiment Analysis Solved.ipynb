{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Emotions Prediction based on content</h2>**\n",
    "Using the dataset, Predict the emotions(happy, sad or angry) based on the contents. Analyze and clean the data using nlp techniques. Finally apply machine learning algorithm for prediction.\n",
    "| Column | Description |\n",
    "|--------|--------------|\n",
    "|  content   |     Textual data  | \n",
    "|  emotion  |    happy, sad or angry   |  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Data loading and observation\n",
    "\n",
    "- Load the dataset named `train_emotion.csv` and store it in the variable `df`. \n",
    "- If the missing value is present, drop it.\n",
    "- Calculate word coverage of first sentence present in the dataset and round off upto two decimal places.   Store it in the variable `coverage`.(Hint: Formula of word coverage = (number of words in sentence / number of unique words in sentence))\n",
    "- Assign a copy of the dataframe to the variable `df_q1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am not your toy.</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ugh. your so fake i bet if you look at the bot...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I smile to the camera, I smile to my friends, ...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If someone breaks your heart, just punch them ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Being grateful to those that harvest our garde...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>['You Hurt Me But I Still Love You.', 'True Lo...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>This man, is man, a man, good man, way man, to...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>Go Ahead, Judge Me. Just Remember To Be Perfec...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>I’m take a nice long shit, so don’t stress me !</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>I knw U Hv Blocked Me, But Still I luv To Watc...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1835 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content emotion\n",
       "0                                    I am not your toy.   angry\n",
       "1     ugh. your so fake i bet if you look at the bot...   angry\n",
       "2     I smile to the camera, I smile to my friends, ...     sad\n",
       "3     If someone breaks your heart, just punch them ...   angry\n",
       "4     Being grateful to those that harvest our garde...   happy\n",
       "...                                                 ...     ...\n",
       "1830  ['You Hurt Me But I Still Love You.', 'True Lo...     sad\n",
       "1831  This man, is man, a man, good man, way man, to...   angry\n",
       "1832  Go Ahead, Judge Me. Just Remember To Be Perfec...   angry\n",
       "1833    I’m take a nice long shit, so don’t stress me !   angry\n",
       "1834  I knw U Hv Blocked Me, But Still I luv To Watc...     sad\n",
       "\n",
       "[1835 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "coverage = round(len(df['content'].iloc[0][0])/len(set(df['content'].iloc[0][0])),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_q1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please check if the variable to the question has been assigned properly\n"
     ]
    }
   ],
   "source": [
    "################ Don't edit or delete the cell, Run this cell to test your code  ################\n",
    "try:\n",
    "    q1 = [df_q1, coverage]\n",
    "    from emotions_predict import emotions\n",
    "    emotions.save_ans1(q1)\n",
    "except:\n",
    "    print(\"Please check if the variable to the question has been assigned properly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Data preprocessing\n",
    "\n",
    "- Create a new column `no_punct` which convert sentence into lower case and removes punctuation from the 'content' column.\n",
    "- Load the 'spacy' model and store it in variable `nlp`.\n",
    "- Complete the function `tokens` which takes text as input and returns list of tokenized word using spacy model.\n",
    "- Apply the function on the `no_punct` column and store the result in a new column called `tokenized`.\n",
    "- Complete the function `remove_stopwords` which takes text as input and returns list of text without stopwords.(Hint: use stopword library)\n",
    "- Apply the function on the `tokenized` column and store the result in a new column called `rem_stop`.\n",
    "- Assign a copy of the dataframe to the variable `df_q2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def no_punct(text):\n",
    "    return ''.join([word for word in text if word not in string.punctuation])\n",
    "df['content']=df['content'].str.lower()\n",
    "df['no_punct']=df['content'].apply(no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 [i, am, not, your, toy]\n",
       "1       [ugh, your, so, fake, i, bet, if, you, look, a...\n",
       "2       [i, smile, to, the, camera, i, smile, to, my, ...\n",
       "3       [if, someone, breaks, your, heart, just, punch...\n",
       "4       [being, grateful, to, those, that, harvest, ou...\n",
       "                              ...                        \n",
       "1830    [you, hurt, me, but, i, still, love, you, true...\n",
       "1831    [this, man, is, man, a, man, good, man, way, m...\n",
       "1832    [go, ahead, judge, me, just, remember, to, be,...\n",
       "1833    [i, ’m, take, a, nice, long, shit, so, do, n’t...\n",
       "1834    [i, knw, u, hv, blocked, me, but, still, i, lu...\n",
       "Name: tokenized, Length: 1835, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp=spacy.load('en_core_web_sm')\n",
    "def tokens(text):\n",
    "    doc=nlp(text)\n",
    "    lister=[]\n",
    "    for word in doc:\n",
    "        lister.append(word.text)\n",
    "    return lister\n",
    "df['tokenized']=df['no_punct'].apply(tokens)\n",
    "df['tokenized']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 [i, am, not, your, toy]\n",
       "1       [ugh, your, so, fake, i, bet, if, you, look, a...\n",
       "2       [i, smile, to, the, camera, i, smile, to, my, ...\n",
       "3       [if, someone, breaks, your, heart, just, punch...\n",
       "4       [being, grateful, to, those, that, harvest, ou...\n",
       "                              ...                        \n",
       "1830    [you, hurt, me, but, i, still, love, you, true...\n",
       "1831    [this, man, is, man, a, man, good, man, way, m...\n",
       "1832    [go, ahead, judge, me, just, remember, to, be,...\n",
       "1833    [i, ’m, take, a, nice, long, shit, so, do, n’t...\n",
       "1834    [i, knw, u, hv, blocked, me, but, still, i, lu...\n",
       "Name: tokenized, Length: 1835, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def remove_stopwords(text):\n",
    "    new=[word for word in text if word not in stopwords.words('english')]\n",
    "    return new\n",
    "df['rem_stop']=df['tokenized'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_q2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if stopwords are to be removed using spacy\n",
    "def remove_stop(text):\n",
    "    doc=nlp(' '.join(text))\n",
    "    final=[word for word in doc if word.is_stop==False]\n",
    "    return final\n",
    "df['rem_stop_spacy']=df['tokenized'].apply(remove_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rem_stop_spacy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################ Don't edit or delete the cell, Run this cell to test your code  ################\n",
    "try:\n",
    "    q2 = [df_q2,nlp]\n",
    "    from emotions_predict import emotions\n",
    "    emotions.save_ans2(q2)\n",
    "except:\n",
    "    print(\"Please check if the variable to the question has been assigned properly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Stemming and lemmatization\n",
    "\n",
    "- Use snow ball Stemmer for performing the Stemming and set language to english alone. \n",
    "- Complete the function `snow_stem` which takes a text as input and returns the list of stemmed version of every word as output. \n",
    "- Apply the function on the `rem_stop` column and store the result in a new column called `Stem_Text`.\n",
    "- Complete the function `lemma` which takes a text as input and returns join of lemmatized word using Wordnet lemmatizer.\n",
    "- Apply function on the `rem_stop` column and store the result in a column called `lemmatized`.\n",
    "- Assign a copy of the dataframe to the variable `df_q3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def snow_stem(text):\n",
    "    snow=SnowballStemmer(language='english')\n",
    "    stemmed=[snow.stem(word) for word in text]\n",
    "    return stemmed\n",
    "df['Stem_Text']=df['rem_stop'].apply(snow_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lemma(text):\n",
    "    lem=WordNetLemmatizer()\n",
    "    lemas=[lem.lemmatize(word) for word in text]\n",
    "    return lemas\n",
    "df['lemmatized']=df['rem_stop'].apply(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_q3 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################ Don't edit or delete the cell, Run this cell to test your code  ################\n",
    "try:\n",
    "    q3 = df_q3\n",
    "    from emotions_predict import emotions\n",
    "    emotions.save_ans3(q3)\n",
    "except:\n",
    "    print(\"Please check if the variable to the question has been assigned properly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Part of Speech tagging\n",
    "\n",
    "- From 'df' dataframe create a new dataframe which contains only first 10 rows of content column and save it into the variable `new_df`.\n",
    "- Complete the function `pos_tag` which takes text as input and returns list of pos tag.(Hint: use spacy model)\n",
    "- Apply the function on the 'content' column and store the result in the new column `pos_tag`.\n",
    "- Assign a copy of the new dataframe(new_df) to the variable `df_q4`.\n",
    "- <b>Example</b>\n",
    "\n",
    "| content | pos_tag |\n",
    "|--------|--------------|\n",
    "| Whatever makes you feel bad, leave it. Whateve...   |     [PRON, VERB, PRON, VERB, ADJ, PUNCT, VERB, PRO...  | \n",
    "|  ['Hating Me Won’T Make You Pretty.', 'Anger Is...   |    [X, PUNCT, VERB, PRON, PROPN, VERB, PRON, PROP...   |  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df = df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag(text):\n",
    "    pos_tagged=nltk.pos_tag(text)\n",
    "    return pos_tagged\n",
    "df['pos_tag']=df['content'].apply(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q4 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Don't edit or delete the cell, Run this cell to test your code  ################\n",
    "try:\n",
    "    q4 = df_q4\n",
    "    from emotions_predict import emotions\n",
    "    emotions.save_ans4(q4)\n",
    "except:\n",
    "    print(\"Please check if the variable to the question has been assigned properly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Named Entity Recognition\n",
    "\n",
    "- Complete the function `ents` which takes text as input and returns list of text and corresponding label.\n",
    "- Apply the function in the new dataframe(new_df) `content` column and store the result into the new column `named_entity`.\n",
    "- Assign a copy of the new dataframe to the variable `df_q5`.\n",
    "- <b>Example</b>\n",
    "\n",
    "| content | pos_tag | named_entity |\n",
    "|--------|--------------|------------|\n",
    "| LoVe ThE oNe WhO LoVeS YoU..... nOt ThE oNe Wh...   |     [NOUN, DET, NUM, PRON, VERB, PRON, PUNCT, PART...  | [(LoVe, ORG), (oNe, CARDINAL), (WhOm, PERSON)]  |\n",
    "|  Whatever makes you feel bad, leave it. Whateve...   |    [PRON, VERB, PRON, VERB, ADJ, PUNCT, VERB, PRO...   |  [] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ents(text):\n",
    "    doc=nlp(text)\n",
    "    lister=[]\n",
    "    for word in doc.ents:\n",
    "        lister.append((word.text,word.label_))\n",
    "    return lister\n",
    "df['named_entity']=df['content'].apply(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['named_entity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q5 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Don't edit or delete the cell, Run this cell to test your code  ################\n",
    "try:\n",
    "    q5 = df_q5\n",
    "    from emotions_predict import emotions\n",
    "    emotions.save_ans5(q5)\n",
    "except:\n",
    "    print(\"Please check if the variable to the question has been assigned properly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Polarity score\n",
    "\n",
    "- Using Sentiment Intensity Analyzer package,find the polarity score of the 'content' column in the new dataframe(new_df).\n",
    "- Store the result into the new column `polarity_score`.\n",
    "- Assign a copy of the new dataframe(new_df) to the variable `df_q6`.\n",
    "- <b>Example</b>\n",
    "\n",
    "| content | pos_tag | named_entity | polarity_score |\n",
    "|--------|--------------|------------|---------------|\n",
    "|  Whatever makes you feel bad, leave it. Whateve...   |    [PRON, VERB, PRON, VERB, ADJ, PUNCT, VERB, PRO...   |  [] | {'neg': 0.273, 'neu': 0.581, 'pos': 0.145, 'compound': -0.296} |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia=SentimentIntensityAnalyzer()\n",
    "df['polarity_score']= df['content'].apply(sia.polarity_scores)\n",
    "df_q6=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Don't edit or delete the cell, Run this cell to test your code  ################\n",
    "try:\n",
    "    q6 = df_q6\n",
    "    from emotions_predict import emotions\n",
    "    emotions.save_ans6(q6)\n",
    "except:\n",
    "    print(\"Please check if the variable to the question has been assigned properly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Feature extraction & model selection\n",
    "\n",
    "- Store `lemmatized` column of `df` dataframe into the variable X and `emotion` column into the variable `y`.\n",
    "- Create an instance of Count Vectorization and store it in variable `count_vect`.\n",
    "- Fit and transform the data extracted (X) and store it in `count_fit`.\n",
    "- Convert it into dataframe and have column as its feature name and store it in the variable `words`.\n",
    "- Split the dataset into training and testing named X_train, X_test, y_train, y_test with the newly transformed data and the emotions with a test size of 20% and random state set to 42.\n",
    "- Fit the model using Linear svc and assign fine tuned model into the variable `model`. Predict it using X_test.\n",
    "- Calculate the accuracy score and round off upto the two decimal places. Store it in variable `acc_score`. Get the classification report of the model and store it in variable `class_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['lemmatized']\n",
    "y = df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_fit = count_vect.fit_transform(X)\n",
    "\n",
    "words = pd.DataFrame(count_fit.toarray(),columns=count_vect.get_feature_names_out())\n",
    "X_train,X_test,y_train,y_test=train_test_split(count_fit,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "acc_score = round(accuracy_score(y_test,y_pred),2)\n",
    "\n",
    "class_report = classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Don't edit or delete the cell, Run this cell to test your code  ################\n",
    "try:\n",
    "    q7 = [words,model,acc_score,class_report]\n",
    "    from emotions_predict import emotions\n",
    "    emotions.save_ans7(q7)\n",
    "except:\n",
    "    print(\"Please check if the variable to the question has been assigned properly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: Prediction\n",
    "\n",
    "- Load the dataset named `validation_emotion.csv` and perform all the data pre-processing tasks in the same manner as the training data.  \n",
    "- Predict the validation dataset and store the result in the variable `y_pred_val` as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=pd.read_csv('validation_emotion.csv')\n",
    "data_test['content']=data_test['content'].str.lower()\n",
    "data_test['no_punct']=data_test['content'].apply(no_punct)\n",
    "data_test['tokenized']=data_test['no_punct'].apply(tokens)\n",
    "data_test['rem_stop']=data_test['tokenized'].apply(remove_stopwords)\n",
    "data_test['Stem_Text']=data_test['rem_stop'].apply(snow_stem)\n",
    "data_test['lemmatized']=data_test['rem_stop'].apply(lemma)\n",
    "data_test['pos_tag']=data_test['content'].apply(pos_tag)\n",
    "data_test['named_entity']=data_test['content'].apply(ents)\n",
    "X=data_test['lemmatized']\n",
    "count_vect = CountVectorizer()\n",
    "count_fit_test = count_vect.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = list(model.predict(count_fit_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Don't edit or delete the cell, Run this cell to test your code  ################\n",
    "try:\n",
    "    q8 = y_pred_val\n",
    "    from emotions_predict import emotions\n",
    "    emotions.save_ans8(q8)\n",
    "except:\n",
    "    print(\"Please check if the variable to the question has been assigned properly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note : After you have finished solving the questions, please run the below cell to save your answers for testing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emotions_predict import emotions\n",
    "try:\n",
    "    q1 = [df_q1, coverage]\n",
    "    q2 = [df_q2,nlp]\n",
    "    q3 = df_q3\n",
    "    q4 = df_q4\n",
    "    q5 = df_q5\n",
    "    q6 = df_q6\n",
    "    q7 = [words,model,acc_score,class_report]\n",
    "    q8 = y_pred_val\n",
    "    emotions.save_answer(q1,q2,q3,q4,q5,q6,q7,q8)\n",
    " \n",
    "except:\n",
    "    print(\"Assign the answers to all the variables properly.\")\n",
    "    emotions.remove_pickle()\n",
    "    try:\n",
    "        q1 = [df_q1, coverage]\n",
    "        emotions.save_ans1(q1)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        q2 = [df_q2,nlp]\n",
    "        emotions.save_ans2(q2)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        q3 = df_q3\n",
    "        emotions.save_ans3(q3)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        q4 = df_q4\n",
    "        emotions.save_ans4(q4)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        q5 = df_q5\n",
    "        emotions.save_ans5(q5)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        q6 = df_q6\n",
    "        emotions.save_ans6(q6)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        q7 = [words,model,acc_score,class_report]\n",
    "        emotions.save_ans7(q7)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        q8 = y_pred_val\n",
    "        emotions.save_ans8(q8)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
